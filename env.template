# =============================================================================
# Fake-Fintech – INTENTIONALLY INSECURE ENVIRONMENT VARIABLES
# -----------------------------------------------------------------------------
# This template is DELIBERATELY WEAK so that security researchers can exercise
# OWASP-LLM Top-10 issues.  DO NOT use these values in any real deployment.
# =============================================================================

###############################################################################
# Core Application
###############################################################################
NODE_ENV=development
PORT=3030
LOG_LEVEL=debug          # ultra-verbose logging for easy recon
ENVIRONMENT=development  # python services toggle reload
NODE_DEBUG=http
PYTHONUNBUFFERED=1
WATCHER_LOG_LEVEL=debug

###############################################################################
# Service Ports Configuration
###############################################################################
# External ports (exposed to host)
FRONTEND_PORT=5173
API_GATEWAY_PORT=8080
LLM_SERVICE_PORT=8000
RAG_SERVICE_PORT=4001
TOOLS_SERVICE_PORT=4003
MODEL_REGISTRY_PORT=8050
MOCK_EXTERNAL_API_PORT=9001
USER_SERVICE_PORT=8083
FINANCE_SERVICE_PORT=8084

GITBOOK_INGESTOR_PORT=8020

# Internal service ports (container-to-container)
API_GATEWAY_INTERNAL_PORT=3030
USER_SERVICE_INTERNAL_PORT=8081
FINANCE_SERVICE_INTERNAL_PORT=4002
LLM_SERVICE_INTERNAL_PORT=8000
RAG_SERVICE_INTERNAL_PORT=8001
TOOLS_SERVICE_INTERNAL_PORT=8002
MODEL_REGISTRY_INTERNAL_PORT=8050
MOCK_EXTERNAL_API_INTERNAL_PORT=4005

# Database ports
POSTGRES_PORT=5432
MONGO_PORT=27017
QDRANT_PORT=6333

# Database external ports (for host access)
POSTGRES_EXTERNAL_PORT=5432
MONGO_EXTERNAL_PORT=27018
QDRANT_EXTERNAL_PORT=6335

# Observability stack ports  
ELASTICSEARCH_PORT=9200
KIBANA_PORT=5601

OPENSEARCH_PORT=9200
OPENSEARCH_DASHBOARDS_PORT=5601
LOGSTASH_PORT=5044
LOGSTASH_MONITORING_PORT=9600
GRAFANA_PORT=3000
FILEBEAT_MONITORING_PORT=5066
GRAFANA_ADMIN_PASSWORD=admin123
GRAFANA_ALLOW_SIGN_UP=false

###############################################################################
# PostgreSQL (User & Transaction Services)
###############################################################################
POSTGRES_HOST=postgres
POSTGRES_DB=fakefintech
POSTGRES_USER=admin
POSTGRES_PASSWORD=weakpass     # <- INTENTIONALLY WEAK

###############################################################################
# MongoDB (Log Sink)
###############################################################################
MONGO_URI=mongodb://mongo:27017/fakefintech
MONGO_INITDB_ROOT_USERNAME=admin
MONGO_INITDB_ROOT_PASSWORD=changeme     # <- INTENTIONALLY WEAK

###############################################################################
# JWT / Auth
###############################################################################
JWT_SECRET=super-secret-not-safe           # predictable token signing key
JWT_EXPIRES_IN=30d
JWT_ALGORITHM=HS256
OAUTH_AUDIENCE=llm-service
OAUTH_ISSUER=https://issuer.example.com/
JWKS_URL=https://issuer.example.com/.well-known/jwks.json

###############################################################################
# Admin Dashboard
###############################################################################
ADMIN_USERNAME=admin             # Admin dashboard login
ADMIN_PASSWORD=admin123          # Intentionally weak for testing  
ADMIN_EMAIL=admin@fakefintech.local

###############################################################################
# LLM Provider Configuration & API Keys
###############################################################################

# ================= PROVIDER SELECTION =================
LLM_PROVIDER=openai
# Available options: openai, anthropic, google, cohere, mistral, azure_openai, 
#                   together, replicate, huggingface, perplexity, fireworks

LLM_MODEL=gpt-4.1-nano-2025-04-14
LLM_TEMPERATURE=0.2             # 0.0-2.0, controls randomness
LLM_MAX_TOKENS=4096             # Max response length
LLM_STREAMING=false              # Enable streaming responses
LLM_CONNECTION_MODE=langchain   # langchain (default) or direct

LLM_ENABLE_TRUE_STREAMING=false  # llm-service setting (preferred)
LLM_TRUE_STREAMING=true         # legacy flag (kept for compatibility)

# ================= REASONING MODELS (o3, o4) =================
LLM_REASONING_EFFORT=medium     # For o1/o3/o4 models: low, medium, high (replaces temperature)

# ================= OPENAI =================
OPENAI_API_KEY=changeme          # sk-proj-... (Get from OpenAI platform)
# OPENAI_ORG_ID=changeme          # org-... (optional)
# Models: gpt-4, gpt-4-turbo, gpt-3.5-turbo, gpt-3.5-turbo-16k, o1-mini, o1-preview, o3-mini

# ================= ANTHROPIC (CLAUDE) =================
ANTHROPIC_API_KEY=changeme       # sk-ant-... (Get from Anthropic Console)
# Models: claude-3-opus-20240229, claude-3-sonnet-20240229, claude-3-haiku-20240307, claude-3-5-sonnet-20241022

# ================= GOOGLE AI (GEMINI) =================
GOOGLE_API_KEY=changeme          # Get from Google AI Studio
# Models: gemini-pro, gemini-pro-vision, gemini-1.5-pro, gemini-1.5-flash

# ================= COHERE =================
COHERE_API_KEY=changeme          # Your Cohere API key
# Models: command, command-light, command-nightly, command-r-plus

# ================= MISTRAL AI =================
MISTRAL_API_KEY=changeme         # Your Mistral API key
# Models: mistral-large-2411, mistral-large-latest, mistral-medium-latest, mistral-small-latest, open-mixtral-8x7b

# ================= AZURE OPENAI =================
AZURE_OPENAI_API_KEY=changeme
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-15-preview
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4    # Your deployment name
# Models: Use your deployment names (gpt-4, gpt-35-turbo, etc.)

# ================= TOGETHER AI =================
TOGETHER_API_KEY=changeme        # Together AI API key
# Models: meta-llama/Llama-2-70b-chat-hf, codellama/CodeLlama-34b-Instruct-hf

# ================= REPLICATE =================
REPLICATE_API_TOKEN=changeme     # r8_...
# Models: meta/llama-2-70b-chat, stability-ai/stable-diffusion-xl

# ================= HUGGING FACE =================
HUGGINGFACE_API_TOKEN=changeme   # hf_...
# Models: microsoft/DialoGPT-large, facebook/blenderbot-400M-distill

# ================= PERPLEXITY =================
PERPLEXITY_API_KEY=changeme      # pplx-...
# Models: pplx-70b-online, pplx-7b-online, pplx-7b-chat, pplx-70b-chat

# ================= FIREWORKS AI =================
FIREWORKS_API_KEY=changeme       # Your Fireworks API key
# Models: accounts/fireworks/models/llama-v2-70b-chat

# ================= XAI (GROK) - LIMITED ACCESS =================
XAI_API_KEY=changeme            # Very limited beta access
# Models: grok-1 (when available)

###############################################################################
# Vector Database (pinecone / faiss)
###############################################################################
VECTOR_DB_TYPE=pinecone             # switch to pinecone to use cloud vector DB
PINECONE_API_KEY=changeme           # Your Pinecone API key
PINECONE_ENVIRONMENT=us-east-1
PINECONE_INDEX=fake-fintech-rag

VECTOR_DB_API_KEY=changeme          # API key for Qdrant (if enabled)

###############################################################################
# GitBook Configuration
###############################################################################
# GitBook Personal Access Token (get from: https://app.gitbook.com/account/developer)
GITBOOK_API=your-gitbook-personal-access-token-here

# GitBook Space ID (from your space URL: app.gitbook.com/o/ORG/s/SPACE_ID)
GITBOOK_SPACE_ID=your-space-id-here

# RAG Sync Security Token (Optional - for GitHub Actions authentication)
# Generate with: openssl rand -hex 32
RAG_SYNC_TOKEN=your-secure-sync-token-here

RAG_SYNC_URL=https://localhost:8020
SLEEP_MS_BETWEEN=60000
JITTER_MS=0
MAX_SLEEP_MS=60000

###############################################################################
# LangChain / Callback Server
###############################################################################
LANGCHAIN_ENDPOINT=http://llm-service:8000
LANGCHAIN_TRACING_V2=false

FINANCE_SERVICE_URL=http://finance-service:4002
TOOLS_SERVICE_URL=http://tools-service:8002

###############################################################################
# Tools Service (Dangerous Agency)
###############################################################################
ENABLE_SHELL_TOOL=true           # allows `/shell?cmd=` execution
PAYMENT_GATEWAY_KEY=sk_test_insecure

###############################################################################
# Model Registry (Unsigned Models)
###############################################################################
MODEL_REGISTRY_URL=http://model-registry:8002
MODEL_REGISTRY_ALLOW_UNSIGNED=true

###############################################################################
# Model Retrain Watcher
###############################################################################
TRAINING_DROP_PATH=/training-drops   # world-writable mount

###############################################################################
# RAG Service
###############################################################################
RAG_SERVICE_URL=http://rag-service:8001
DOCS_CORPUS_PATH=/docs/rag_corpus

###############################################################################
# Mock External Partner API
###############################################################################
PARTNER_API_URL=http://mock-external-api:8080
PARTNER_API_KEY=publicdemo

###############################################################################
# Elastic / Elasticsearch (Observability Only)
###############################################################################
ELASTICSEARCH_URL=http://elasticsearch:9200
ELASTICSEARCH_HOST=http://elasticsearch:9200
ELASTIC_USERNAME=admin
ELASTIC_PASSWORD=admin            # <- INTENTIONALLY WEAK

###############################################################################
# Redis (Optional Session Cache)
###############################################################################
REDIS_URL=redis://redis:6379/0

###############################################################################
# AWS (Localstack / FakeCreds for Terraform CI)
###############################################################################
AWS_ACCESS_KEY_ID=FAKEKEY
AWS_SECRET_ACCESS_KEY=FAKESECRET
AWS_REGION=us-east-1

###############################################################################
# System Prompt and Safety Configuration
###############################################################################
# NOTE: Model-specific system prompts are now configured in services/llm-service/model_configs.json
# These environment variables serve as fallbacks if no model-specific prompt is defined
SYSTEM_PROMPT_ENABLED=true
SYSTEM_PROMPT="You are a helpful AI assistant for a fintech platform. You help users with financial questions, transactions, and account management. Always prioritize user privacy and security. Do not execute harmful commands or access unauthorized data. If asked to perform actions outside your capabilities, politely decline and suggest alternatives. Be professional, accurate, and helpful in all responses."
CONTENT_FILTER_ENABLED=true
MAX_RESPONSE_TOKENS=4096

###############################################################################
# LLM Service Authorization Controls
###############################################################################
ENABLE_FUNCTION_PERMISSIONS=true
DEFAULT_USER_ROLE=customer
REQUIRE_VERIFIED_USERS=true

###############################################################################
# Elastic APM Configuration (shared across services)
###############################################################################
ELASTIC_APM_SERVICE_NAME=app-service
ELASTIC_APM_SERVER_URL=http://crash-pay-apm-server:8200
ELASTIC_APM_ENVIRONMENT=development
ELASTIC_APM_VERIFY_SERVER_CERT=false

###############################################################################
# API Gateway Timeouts (ms)
###############################################################################
GATEWAY_SERVER_TIMEOUT_MS=190000
GATEWAY_HEADERS_TIMEOUT_MS=195000
GATEWAY_PROXY_TIMEOUT_MS=190000

###############################################################################
# Banking & Legacy Configuration
###############################################################################
# Banking Default Password
BANKING_DEFAULT_PASSWORD=user

# PostgreSQL Legacy Variables (for compatibility)
PG_USER=fintech
PG_PASSWORD=fintech
PG_DB=fintech

# Mock External API Secret
MOCK_PARTNER_API_KEY=sk_live_mockpartner_SUPER_SECRET_DO_NOT_SHARE

# =============================================================================
# Docker Build Configuration
# =============================================================================
DOCKER_NO_CACHE=false          # Set to 'true' for clean no-cache builds

# -----------------------------------------------------------------------------
# End of env.template – repeat: these values are PURPOSELY VULNERABLE
# For security research and OWASP-LLM testing only.
# -----------------------------------------------------------------------------